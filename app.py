
# ============================
# INICIO: Librer√≠as
# - Orden de carga intencional:
#   1) Computaci√≥n y tiempo (numpy, time)
#   2) Visi√≥n (cv2)
#   3) Web (streamlit)
#   4) Modelo IA (ultralytics.YOLO)
#   5) Audio (pygame), con fallback seguro
#   Motivo: mantener inicializaci√≥n predecible y mensajes claros en caso de fallos.
# ============================
import cv2
import time
import numpy as np
import streamlit as st
from ultralytics import YOLO

# ============================
# INPUT: Variables y par√°metros iniciales
# Prop√≥sito pedag√≥gico:
# - Declarar expl√≠citamente cada recurso (audio, IA, c√°mara, focal)
# - Documentar supuestos y l√≠mites (clases, alturas, umbrales, NA)
# - Asegurar trazabilidad para no videntes mediante resumen textual consistente.
# ============================

# --- Audio ---
# - AUDIO_ENABLED controla si se intentar√° reproducir pitidos (accesibilidad auditiva).
# - BEEP_FILE es el recurso de sonido (mono, corto, no intrusivo).
# - La inicializaci√≥n de pygame usa par√°metros conservadores para baja latencia.
# - Si falla cualquier paso (archivo ausente, mixer no disponible), se desactiva audio
#   sin romper el flujo principal (detecci√≥n y visualizaci√≥n contin√∫an).
AUDIO_ENABLED = True
BEEP_FILE = "beep.wav"
try:
    import pygame
    pygame.mixer.init(frequency=44100, size=-16, channels=1, buffer=512)
    beep_sound = pygame.mixer.Sound(BEEP_FILE)
except Exception:
    AUDIO_ENABLED = False
    beep_sound = None

# --- Modelo YOLO ---
# - yolov8s.pt: modelo liviano para tiempo real en CPU; ajusta a "n" o "m" seg√∫n hardware.
# - verbose se controla m√°s adelante para no llenar la interfaz.
model = YOLO("yolov8s.pt")

# --- Clases relevantes con alturas arbitrarias de ejemplo ---
# - size_m: dimensi√≥n real aproximada para inferir distancia (pinhole).
# - axis: eje de medici√≥n preferente (height por estabilidad en pedestres).
# - Nota: Son valores pedag√≥gicos; en producci√≥n calibrar por clase y c√°mara.
CLASS_REAL_SIZE = {
    "person": {"size_m": 1.65, "axis": "height"},
    "car": {"size_m": 1.80, "axis": "height"},
    "bus": {"size_m": 2.50, "axis": "height"},
    "truck": {"size_m": 2.50, "axis": "height"},
    "motorcycle": {"size_m": 1.60, "axis": "height"},
    "bicycle": {"size_m": 1.60, "axis": "height"},
}
TARGET_CLASSES = set(CLASS_REAL_SIZE.keys())

# --- Ajuste focal ---
# - STATE["focal_px"] proviene de una calibraci√≥n previa (pinhole).
# - Mantener en estado global para trazabilidad y actualizaci√≥n futura.
STATE = {"focal_px": 327.62}

# --- Control de audio ---
# - last_beep_time evita saturaci√≥n auditiva. Intervalos dependen de distancia y tipo.
last_beep_time = 0.0

# ============================
# DEFINIR OPERACIONES: Funciones auxiliares
# Dise√±o:
# - Cada funci√≥n tiene responsabilidad √∫nica y comentarios de entrada/salida.
# - No lanzan excepciones (devuelven None o silencian), para continuidad pedag√≥gica.
# ============================

def pick_axis_size(box, axis="height"):
    """
    Devuelve el tama√±o del eje solicitado a partir de una caja (x1, y1, x2, y2).

    Par√°metros:
    - box: tupla (x1, y1, x2, y2) en p√≠xeles
    - axis: "height" o "width"

    Retorna:
    - int tama√±o en px, m√≠nimo 1 para evitar divisi√≥n por cero.

    Justificaci√≥n:
    - height es m√°s estable para personas. width puede variar por pose/inclinaci√≥n.
    """
    x1, y1, x2, y2 = box
    w = max(1, x2 - x1)
    h = max(1, y2 - y1)
    return w if axis == "width" else h

def estimate_distance(size_px, H_real_m, focal_px):
    """
    Calcula distancia aproximada con c√°mara pinhole:
    D ‚âà (H_real_m * focal_px) / size_px

    Par√°metros:
    - size_px: tama√±o en p√≠xeles del eje elegido
    - H_real_m: altura (o ancho) real mapeada a la clase
    - focal_px: distancia focal efectiva en p√≠xeles (calibrada)

    Retorna:
    - float con metros, o None si no es posible calcular (evita fallos).
    """
    if focal_px <= 0 or size_px <= 0:
        return None
    return (H_real_m * focal_px) / size_px

def beep_progresivo(D, tipo):
    """
    Genera pitido progresivo seg√∫n distancia y tipo de objeto.
    Pol√≠ticas:
    - Personas: umbrales m√°s sensibles (proximidad cr√≠tica a 2 m).
    - Veh√≠culos: umbrales m√°s amplios (proximidad cr√≠tica a 3 m).
    - Se limita la frecuencia de pitidos con last_beep_time.

    Seguridad:
    - Si AUDIO_ENABLED es False o D es None, no hace nada.
    - Cualquier excepci√≥n en el mixer se silencia.

    Accesibilidad:
    - Volumen y ritmo aumentan cuando el objeto se acerca, para clara percepci√≥n auditiva.
    """
    global last_beep_time
    if not AUDIO_ENABLED or D is None:
        return
    now = time.time()
    if tipo == "person":
        if D > 10: return
        if D > 5: interval, vol = 1.0, 0.2
        elif D > 2: interval, vol = 0.6, 0.5
        else: interval, vol = 0.3, 0.9
    else:
        if D > 10: return
        if D > 6: interval, vol = 1.0, 0.3
        elif D > 3: interval, vol = 0.6, 0.6
        else: interval, vol = 0.3, 0.9
    if now - last_beep_time < interval:
        return
    last_beep_time = now
    try:
        if beep_sound is not None:
            beep_sound.set_volume(vol)
            beep_sound.play()
    except Exception:
        pass

def auto_camera_index(max_test=3):
    """
    Detecta autom√°ticamente la primera c√°mara disponible.
    - Prueba √≠ndices [0..max_test-1].
    - Retorna el √≠ndice o None si no hay c√°mara.

    Motivo:
    - Facilitar despliegue en distintos equipos sin configuraci√≥n manual.
    """
    for i in range(max_test):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            cap.release()
            return i
    return None

# ============================
# PROCESO DE LAS OPERACIONES: Detecci√≥n y c√°lculo
# - Enfocado en mantener tiempo real y trazabilidad textual.
# - Pol√≠ticas de descarte:
#   * conf < 0.70: no se contabiliza ni se muestra (pedag√≥gicamente coherente).
#   * cls fuera de TARGET_CLASSES: se ignora (evita ruido).
# - Reporte:
#   * Siempre mostrar distancias aceptadas; si se descarta no se reporta (consistencia).
# - Alarmas:
#   * Persona: D < 2 m, o caja dominante (ratio_w > 0.45 o ratio_h > 0.60).
#   * Veh√≠culo: D < 3 m, o ratio_h > 0.60 (ocupa gran parte de pantalla).
# ============================

def procesar(frame, frame_count):
    """
    Ejecuta inferencia, calcula distancias, decide color y arma resumen textual.

    Retorna:
    - annotated: imagen con cajas y etiquetas coloreadas
    - resumen_text: texto multi-l√≠nea con conteos, distancias y estado de alarma
    """
    results = model(frame, imgsz=320, verbose=False)[0]
    annotated = frame.copy()
    resumen = []
    fpx = STATE["focal_px"]
    h_img, w_img = frame.shape[:2]
    alarma = False
    count_personas, count_vehiculos = 0, 0
    distancias_personas, distancias_vehiculos = [], []

    # ============================
    # PROCESO DE DECISI√ìN: Condiciones y bucles
    # ============================
    for box in results.boxes:
        cls = model.names[int(box.cls)]
        conf = float(box.conf)

        # 1) Filtro por confianza y clase de inter√©s
        if conf < 0.70 or cls not in TARGET_CLASSES:
            # No se reporta para evitar contradicciones en salida
            continue

        # 2) Calcular distancia con pinhole, usando eje recomendado por clase
        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
        axis = CLASS_REAL_SIZE[cls]["axis"]
        H_real = CLASS_REAL_SIZE[cls]["size_m"]
        size_px = pick_axis_size((x1, y1, x2, y2), axis)
        D = estimate_distance(size_px, H_real, fpx)

        # 3) Calcular zona horizontal (izquierda/centro/derecha) para orientaci√≥n auditiva/textual
        cx = (x1 + x2) // 2
        if cx < w_img / 3:
            zona = "izquierda"
        elif cx < 2 * w_img / 3:
            zona = "centro"
        else:
            zona = "derecha"

        # 4) Ratios relativos (tama√±o de caja respecto a la imagen)
        #    Ayudan a detectar ocupaci√≥n dominante aunque D sea None (por geometr√≠a o oclusi√≥n).
        box_width = x2 - x1
        ratio_w = box_width / w_img
        box_height = y2 - y1
        ratio_h = box_height / h_img

        # 5) Decisiones por tipo
        if cls == "person":
            count_personas += 1
            if D is not None:
                distancias_personas.append(D)
                beep_progresivo(D, "person")
            # Persona: alarma si D < 2 m o si ocupa √°rea significativa
            if (D is not None and D < 2.0) or ratio_w > 0.45 or ratio_h > 0.60:
                alarma = True
        else:
            count_vehiculos += 1
            if D is not None:
                distancias_vehiculos.append(D)
                # Nota: usamos "vehiculo" para la l√≥gica interna de audio (no afecta visual)
                beep_progresivo(D, "vehiculo")
            # Veh√≠culo: alarma si D < 3 m o si ocupa vertical dominante
            if (D is not None and D < 3.0) or ratio_h > 0.60:
                alarma = True

        # 6) Color seg√∫n proximidad (verde/amarillo/naranja/rojo)
        #    - Rojo: cr√≠tico, umbral por tipo
        #    - Naranja: media proximidad
        #    - Amarillo: lejana pero relevante
        #    - Verde: seguro
        color = (0, 255, 0)
        if D is not None:
            if (cls == "person" and D < 2) or (cls != "person" and D < 3):
                color = (0, 0, 255)          # rojo
            elif (cls == "person" and D < 5) or (cls != "person" and D < 6):
                color = (0, 165, 255)        # naranja
            elif D < 10:
                color = (0, 255, 255)        # amarillo

        # ============================
        # RESULTADOS parciales (visual + texto)
        # ============================
        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
        label = f"{cls} {conf:.2f} | {D if D is not None else 'NA'}m | {zona}"
        cv2.putText(annotated, label, (x1, max(0, y1 - 10)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        resumen.append(label)

    # ============================
    # DECISI√ìN: RESULTADOS finales (texto accesible)
    # - Siempre incluir conteos por tipo.
    # - Listar distancias aceptadas (no incluir descartadas).
    # - Mensaje de alarma din√°mico (solo si alguna condici√≥n se activ√≥).
    # ============================
    if alarma:
        resumen.append("üö® ALARMA: objeto o se√±al cerca")
    resumen.append(f"üë• Personas: {count_personas}")
    if distancias_personas:
        resumen.append("   Distancias: " + ", ".join(f"{d:.2f}m" for d in distancias_personas))
    resumen.append(f"üöó Veh√≠culos: {count_vehiculos}")
    if distancias_vehiculos:
        resumen.append("   Distancias: " + ", ".join(f"{d:.2f}m" for d in distancias_vehiculos))
    if not resumen:
        resumen = ["‚ùì Nada detectado"]

    return annotated, "\n".join(resumen)


# ============================
# OUTPUT: Visualizaci√≥n y control en web (STREAMLIT)
# Estructura:
# - header: contexto de c√°mara del servidor
# - placeholders: imagen y texto con actualizaci√≥n en bucle
# - control: checkbox para iniciar/detener
# Robustez:
# - Mensajes de error/advertencia claros (no bloquean app completa)
# - Release de recursos al finalizar
# ============================

st.header("C√°mara del servidor (compartida)")
frame_placeholder = st.empty()
text_placeholder = st.empty()

# Detecci√≥n autom√°tica de c√°mara (entorno local/servidor)
cam_index = auto_camera_index()
if cam_index is None:
    st.error("‚ö†Ô∏è No se encontr√≥ ninguna c√°mara disponible")
else:
    cap = cv2.VideoCapture(cam_index)
    run = st.checkbox("Iniciar c√°mara")

    frame_count = 0
    while run:
        ret, frame = cap.read()
        if not ret:
            st.warning("‚ö†Ô∏è No se pudo acceder a la c√°mara")
            break

        # OUTPUT EN LA WEB
        annotated, resumen = procesar(frame, frame_count)
        # Convertimos BGR->RGB para visualizaci√≥n correcta en web
        frame_placeholder.image(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
        # Texto accesible con decisiones y distancias
        text_placeholder.text(resumen)

        frame_count += 1

    # Liberaci√≥n de recursos (c√°mara y ventanas)
    cap.release()
    cv2.destroyAllWindows()

